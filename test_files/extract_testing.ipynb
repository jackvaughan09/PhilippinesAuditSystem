{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as p\n",
    "import config as conf\n",
    "import os\n",
    "import pandas as pd\n",
    "import tabula.io as tb\n",
    "from extracttools import good_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polish(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # remove \\r characters\n",
    "    df = df.rename(lambda s:s.replace('\\r',' '),axis='columns') # remove '\\r' from headers\n",
    "    df = df.replace('\\r','',regex=True) # replace all '\\r' throughout\n",
    "    # approximate headers\n",
    "    cols = df.columns\n",
    "    newcols = [good_match(col,conf.CANON_HEADERS) for col in cols]\n",
    "    df.columns = newcols\n",
    "    print(df.columns)\n",
    "    return df\n",
    "def is_header(row):\n",
    "    if sum([bool(any([fuzz.token_sort_ratio(cell,target) > 60 for target in ref])) for cell in head.loc[row]]) < 2:\n",
    "        \"\"\" nonsense case -> treat as overflow \"\"\"\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def separate_overflow(df,ind,page_range) -> list[pd.DataFrame]:\n",
    "    # step 1 - find where table actually begins\n",
    "    start = 0\n",
    "    for row in range(len(df)):\n",
    "        print(row)\n",
    "        if is_header(df.loc[row]):\n",
    "            start = row\n",
    "            print('is header')\n",
    "    if start == 0:\n",
    "        if not is_header(df.loc[0]):\n",
    "            if not df.empty: # case 2: no row resembling a header found\n",
    "                df.columns = conf.CANON_HEADERS # could result in mismatched headers\n",
    "                raise(BaseException('Could result in mismatched headers on p.'+str(int(page_range.split('-')[0])+ind)))\n",
    "    overflow = df.loc[0:start]\n",
    "    df.drop([i for i in range(0,start)])\n",
    "    df.columns = df.loc[start]\n",
    "    df.reset_index()\n",
    "    return [df,overflow]\n",
    "def fix_overflow(dfs: list[pd.DataFrame],page_range: str) -> list[pd.DataFrame]:\n",
    "    print('SHOW UP DAMMIT!')\n",
    "    for i,df in enumerate(dfs[1:]):\n",
    "        print('why isn\\'t this printing?')\n",
    "        [df,overflow] = separate_overflow(df,i,page_range)\n",
    "        # if sum([col != '' for col in overflow]) <= 2: # merging with last row on prev page TODO\n",
    "        if 0 == sum([s in overflow['observations and recommendations'][0] for s in conf.BULLET_STRS],[s in overflow['audit observation'][0] for s in conf.BULLET_STRS]):\n",
    "            dfs[i-1].loc[-1] += overflow\n",
    "        dfs[i-1].append(overflow)\n",
    "    print('OVERFLOW: '+overflow)\n",
    "    return dfs\n",
    "def longest_seq(li: list):\n",
    "    longest = []\n",
    "    seq = [li[0]]\n",
    "    longest_streak = 0\n",
    "    streak = 0\n",
    "    for i in range(len(li)-1):\n",
    "        if li[i] == li[i+1]-1:\n",
    "            seq = seq + [li[i+1]]\n",
    "            streak = streak + 1\n",
    "        else:\n",
    "            streak = 0\n",
    "            seq = [li[i+1]]\n",
    "        if longest_streak < streak:\n",
    "            longest_streak = streak\n",
    "            longest = seq\n",
    "    return longest\n",
    "def get_pg_rng(pdf_url):\n",
    "    pdf = p.PdfFileReader(pdf_url)\n",
    "    n = pdf.numPages\n",
    "    outp = ''\n",
    "    pgs = list()\n",
    "    for pg in range(n):\n",
    "        page = pdf.getPage(pg)\n",
    "        content = page.extractText()\n",
    "        if all([target in content.lower() for target in conf.TARGET_SENTENCE]):\n",
    "            pgs = pgs + [pg]\n",
    "    if len(pgs) < 1:\n",
    "        print('Warning: No pages contain tables: '+pdf_url)\n",
    "        return '0'\n",
    "    elif len(pgs) < 2: \n",
    "        pgs = [pg for pg in range(pgs[0],n)]\n",
    "        print('Warning: Only 1 page was detected containing target title')\n",
    "        return str(min(pgs)+1) + '-' + str(max(pgs)+1)\n",
    "    elif longest_seq(pgs) == []:\n",
    "        print('Warning: May have missed a document')\n",
    "        return '0' # when this occurred, it was the wrong table\n",
    "    else:\n",
    "        pgs = longest_seq(pgs) # assume that the area with the most instances of the target sequence words\n",
    "                           # is where Part IV actually begins as opposed to some front matter or table of contents\n",
    "        pgs = [pg for pg in range(pgs[0],n)] # scrape starting from official beginning of Part IV until the end of the document\n",
    "        return str(min(pgs)+1) + '-' + str(max(pgs)+1)\n",
    "def city(df:pd.DataFrame,pdf_url:str)->pd.DataFrame:\n",
    "    df = df.assign(city=''.join([c for c in ((pdf_url.split('/')[-1])[2:].split('_'))[0].replace('-','') if ord(c) >= 65]))\n",
    "    for cell in df['city']:\n",
    "        if cell in list(conf.ABBREV_CITY_NAMES.keys()):\n",
    "            df = df.assign(city = conf.ABBREV_CITY_NAMES[cell])\n",
    "    return df\n",
    "def year(df:pd.DataFrame,pdf_url:str)->pd.DataFrame:\n",
    "    return df.assign(year=''.join([c for c in ((pdf_url.split('/')[-1])[2:].split('_'))[0].replace('-','') if ord(c) < 65]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(pdf_url) -> pd.DataFrame:\n",
    "    pg_rng = get_pg_rng(pdf_url)\n",
    "    if pg_rng == '0':\n",
    "        return\n",
    "    print(pg_rng)\n",
    "    dfs = tb.read_pdf(input_path = pdf_url, output_format = 'dataframe', pages = pg_rng, lattice = True, multiple_tables = True)\n",
    "    dfs = [polish(df) for df in dfs]\n",
    "    print('fix_overflow print()\\'s won\\'t print')\n",
    "    dfs = [dfs[0]]+[fix_overflow(dfs,pg_rng) for df in dfs[1:]]\n",
    "    print(dfs[0]['audit observation'])\n",
    "    dfs = [year(city(df,pdf_url),pdf_url) for df in dfs]\n",
    "    out = pd.concat(dfs,ignore_index=True,axis=0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56-75\n",
      "Index(['audit observation', 'recommendations', 'ref', 'management action',\n",
      "       'status of implementation', 'reasons for partial/non-implementation'],\n",
      "      dtype='object')\n",
      "fix_overflow print()'s won't print\n",
      "0     Non-settingupofRPT/SET Receivables1.RealProper...\n",
      "1     UnrecordedInterest Income2.   Failure to recor...\n",
      "2                                                   NaN\n",
      "3                           AuditObservations (CY 2009)\n",
      "4     Understated InsuranceExpense.    The expired p...\n",
      "5     Uncancelled StaleChecks4.Stalechecksamounting ...\n",
      "6                           AuditObservations (CY 2009)\n",
      "7     Unadjusted InventoryAccount With No StockBalan...\n",
      "8     Unreconciled Differencein Inventory Reports6.T...\n",
      "9                           AuditObservations (CY 2009)\n",
      "10    ErroneousClassification ofPayable Accounts7.  ...\n",
      "11    Dormant OtherReceivables Account8.Despite  pre...\n",
      "12                          AuditObservations (CY 2009)\n",
      "13    overstatement of agencyassets due to theinclus...\n",
      "14    Non-payment of Loans10.  Of the P6,569,823.36r...\n",
      "15                          AuditObservations (CY 2009)\n",
      "16                                                  NaN\n",
      "17    Tight Cash Position11.  The Cash balance ofP10...\n",
      "18    Low CollectionEfficiency12.OftheP37,953,172.98...\n",
      "19                          AuditObservations (CY 2009)\n",
      "20    SuspendedTransactions13.LGUâ€™stotalunsettledsus...\n",
      "21    DisallowedTransactions14.Totalunsettleddisallo...\n",
      "22                          AuditObservations (CY 2009)\n",
      "23    Understatement of PPEaccounts15.   Completed p...\n",
      "24    Violations  of  Laws  andRegulations16.   The ...\n",
      "25                          AuditObservations (CY 2009)\n",
      "26                                                  NaN\n",
      "27    Doubtful Validity in theCollection of ServiceF...\n",
      "28    DeficienciesintheProcurement Process18.   The ...\n",
      "29                          AuditObservations (CY 2009)\n",
      "30                                                  NaN\n",
      "31    ProcurementMonitoringReport (PMR) and did notu...\n",
      "32                          AuditObservations (CY 2009)\n",
      "33                       GENDERANDDEVELOPMENT(GAD)AUDIT\n",
      "34    Absence of GAD Plan19.  The failure to prepare...\n",
      "35                          AuditObservations (CY 2009)\n",
      "36    20% DEVELOPMENTFUNDSlow delivery ofservices & ...\n",
      "37                          AuditObservations (CY 2008)\n",
      "38    Dormant OtherReceivables Account22.Other  Rece...\n",
      "39    uspended Transactions23.Totalunsettledsuspende...\n",
      "40                          AuditObservations (CY 2008)\n",
      "41    24.OfthetotalAppropriated/AllottedAmountofP50,...\n",
      "42                          AuditObservations (CY 2008)\n",
      "43    Value For Money Audit25. The LGU did not follo...\n",
      "44    26.TheLGUdidnotappropriatelyearmarktheborrowin...\n",
      "45                           AuditObservations (CY2007)\n",
      "46    InsufficientCollectionsfor the Real Property T...\n",
      "47    Findings on InformationSystems Audit28.  The  ...\n",
      "48                          AuditObservations (CY 2007)\n",
      "49    29.Collection  reportsgeneratedbytheRPTSystemo...\n",
      "50                          AuditObservations (CY 2007)\n",
      "51    30.Forty-eightpercent(48%)orP24,509,238.65wort...\n",
      "52    31.  Had the water systemsbeenoperatedbythebar...\n",
      "53                          AuditObservations (CY 2006)\n",
      "54    33.Onlysixoutofthethirteenparcelsoflandvalued ...\n",
      "Name: audit observation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = extract('../test_data/pdf/01-IGACOS2010_Audit_Report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5709eba2b967cfe803191a09c675f79c4bb908bd59fde2c9952cb2071f8ee3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
