{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Investigation --> Training Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PyPDF2 as p\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "import philaudit as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../run_logs/part3_pgs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find error files and save them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = df.loc[df.part3_range.str.contains(\"Error\")]\n",
    "print(errors.shape)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.to_csv(\"../run_logs/part3_errors.csv\")\n",
    "df = df.loc[~df.part3_range.str.contains(\"Error\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find files with fractured ranges\n",
    "\n",
    "These come from removing blank pages and pages without tables from the detected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_range_files = df.loc[df.part3_range.apply(lambda x: len(eval(x))>1), 'file'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(broken_range_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the range objects and concatenate them to a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_ranges(lst):\n",
    "    net = []\n",
    "    for rng in lst:\n",
    "        net.extend(rng)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expanded']=(\n",
    "    df.part3_range\n",
    "    .apply(lambda x: eval(x))\n",
    "    .apply(lambda y: list(y[0]) if len(y)==1 else unpack_ranges(y)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expanded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Expanded` investigation\n",
    "\n",
    "Finding files that need to be tested individually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_ranges = df.loc[df.expanded.apply(len) > 30]\n",
    "print(long_ranges.shape)\n",
    "long_ranges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_broken_ranges = long_ranges.loc[\n",
    "    long_ranges.file.apply(lambda x: x in broken_range_files)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_broken_ranges.shape)\n",
    "long_broken_ranges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_these_to_new_test_folder(long_broken_ranges):\n",
    "    files = long_broken_ranges.file.to_list()\n",
    "    for file in files:\n",
    "        shutil.move(file, \"./philaudit/test/new_testers/\")\n",
    "# move_these_to_new_test_folder(long_broken_ranges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"predictions\" df for all files\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [file for file in os.listdir(\"./philaudit/test/pdf/\") if file.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliver = df.loc[df.file.apply(lambda x: x.split('/')[-1]).isin(test_files)]\n",
    "sliver = sliver.reset_index(drop=True)\n",
    "sliver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.file.str.contains(\"Pidigan2011\")]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include = []\n",
    "exclude = []\n",
    "# 1. remove the long_broken_ranges from df\n",
    "# Now we have only files for which my current algorithm works\n",
    "# Checkout philaudit/test for more details\n",
    "# 2. for each of the good documents, we just take the difference between \n",
    "# the indicies in reader.pages[] from the extended range\n",
    "# 3. leftover of reader.pages[] will be exclude and vice versa for include \n",
    "#   --> easy labeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = long_broken_ranges.index.to_list()\n",
    "df = df.drop(to_remove, axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('broken', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['include'] = df.expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exclusion_pages_data_for_file(file, include):\n",
    "    reader = p.PdfReader(file)\n",
    "    include = set(include)\n",
    "    pages = set(i for i in range(0, len(reader.pages)))\n",
    "    exclude = pages - include\n",
    "    return list(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_data = []\n",
    "for _, row in df.iterrows():\n",
    "    file = row.file\n",
    "    include = row.include\n",
    "    exclude = generate_exclusion_pages_data_for_file(file, include)\n",
    "    ex_data.append(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exclude'] = ex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>part3_range</th>\n",
       "      <th>expanded</th>\n",
       "      <th>include</th>\n",
       "      <th>exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./pdf/09-Bongabong2013_Part3-Status_of_PY's_Re...</td>\n",
       "      <td>[range(0, 24)]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./pdf/01-Umingan2013_Audit_Report.pdf</td>\n",
       "      <td>[range(76, 79)]</td>\n",
       "      <td>[76, 77, 78]</td>\n",
       "      <td>[76, 77, 78]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./pdf/05-Binalbagan2013_Part3-Status_of_Implem...</td>\n",
       "      <td>[range(0, 8)]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./pdf/01-Sallapadan2012_Audit_Report.pdf</td>\n",
       "      <td>[range(60, 71)]</td>\n",
       "      <td>[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]</td>\n",
       "      <td>[60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./pdf/01-Sudipen2013_Audit_Report.pdf</td>\n",
       "      <td>[range(41, 48)]</td>\n",
       "      <td>[41, 42, 43, 44, 45, 46, 47]</td>\n",
       "      <td>[41, 42, 43, 44, 45, 46, 47]</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file      part3_range  \\\n",
       "0  ./pdf/09-Bongabong2013_Part3-Status_of_PY's_Re...   [range(0, 24)]   \n",
       "1              ./pdf/01-Umingan2013_Audit_Report.pdf  [range(76, 79)]   \n",
       "2  ./pdf/05-Binalbagan2013_Part3-Status_of_Implem...    [range(0, 8)]   \n",
       "3           ./pdf/01-Sallapadan2012_Audit_Report.pdf  [range(60, 71)]   \n",
       "4              ./pdf/01-Sudipen2013_Audit_Report.pdf  [range(41, 48)]   \n",
       "\n",
       "                                            expanded  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1                                       [76, 77, 78]   \n",
       "2                           [0, 1, 2, 3, 4, 5, 6, 7]   \n",
       "3       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]   \n",
       "4                       [41, 42, 43, 44, 45, 46, 47]   \n",
       "\n",
       "                                             include  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1                                       [76, 77, 78]   \n",
       "2                           [0, 1, 2, 3, 4, 5, 6, 7]   \n",
       "3       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]   \n",
       "4                       [41, 42, 43, 44, 45, 46, 47]   \n",
       "\n",
       "                                             exclude  \n",
       "0                                                 []  \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "2                                                [8]  \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = './pdf'\n",
    "output_folder = './target_page_detection/training_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_images(pdf_path, output_folder):\n",
    "    images = convert_from_path(pdf_path, fmt='png')\n",
    "    filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    for idx, img in enumerate(images):\n",
    "        img_path = os.path.join(output_folder, f\"{filename}_page_{idx + 1}.png\")\n",
    "        img.save(img_path, 'png')\n",
    "\n",
    "def move_images_to_categories(df, output_folder):\n",
    "    for _, row in df.iterrows():\n",
    "        filename = row.file.split('/')[-1][:-4]\n",
    "        include_indexes = row.include\n",
    "        exclude_indexes = row.exclude\n",
    "\n",
    "        for idx in include_indexes:\n",
    "            src_path = os.path.join(output_folder, f\"{filename}_page_{idx + 1}.png\")\n",
    "            dest_path = os.path.join(output_folder, 'include', f\"{filename}_page_{idx + 1}.png\")\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "        for idx in exclude_indexes:\n",
    "            src_path = os.path.join(output_folder, f\"{filename}_page_{idx + 1}.png\")\n",
    "            dest_path = os.path.join(output_folder, 'exclude', f\"{filename}_page_{idx + 1}.png\")\n",
    "            shutil.move(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDFs to images and move them to the correct folders\n",
    "# for path in df['file']:\n",
    "#     convert_pdf_to_images(path, output_folder)\n",
    "\n",
    "move_images_to_categories(df, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
